{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "efd338af",
   "metadata": {},
   "source": [
    "## Appendix-2: Logistic Regression\n",
    "\n",
    "Logistic Regression is a binary classification algorithm that can be extended to multiclass classification by using one-vs-rest or softmax. It is a linear model that learns a weight vector and a bias term to map the input features to a probability score. \n",
    "\n",
    "For our implementation, we used scikit-learn's LogisticRegression classifier with the default L2 regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10dea8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import library dependencies\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import learning_curve\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a13c67",
   "metadata": {},
   "source": [
    "#### Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c753635c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_PATH='../'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e8ccef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to open pickle file\n",
    "def unpickle(file):\n",
    "    import pickle\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4dcc00d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# store each pickle files in individual batches\n",
    "batch1 = unpickle(ROOT_PATH+\"cifar-10-batches-py/data_batch_1\")\n",
    "batch2 = unpickle(ROOT_PATH+\"cifar-10-batches-py/data_batch_2\")\n",
    "batch3 = unpickle(ROOT_PATH+\"cifar-10-batches-py/data_batch_3\")\n",
    "batch4 = unpickle(ROOT_PATH+\"cifar-10-batches-py/data_batch_4\")\n",
    "batch5 = unpickle(ROOT_PATH+\"cifar-10-batches-py/data_batch_5\")\n",
    "test_batch = unpickle(ROOT_PATH+\"cifar-10-batches-py/test_batch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66a05f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to create labels and images from data\n",
    "def load_data0(btch):\n",
    "    labels = btch[b'labels']\n",
    "    imgs = btch[b'data'].reshape((-1, 32, 32, 3))\n",
    "    \n",
    "    res = []\n",
    "    for ii in range(imgs.shape[0]):\n",
    "        img = imgs[ii].copy()\n",
    "        img = np.fliplr(np.rot90(np.transpose(img.flatten().reshape(3,32,32)), k=-1))\n",
    "        res.append(img)\n",
    "    imgs = np.stack(res)\n",
    "    return labels, imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "33a636f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to load data into training and test set\n",
    "def load_data():\n",
    "    x_train_l = []\n",
    "    y_train_l = []\n",
    "    for ibatch in [batch1, batch2, batch3, batch4, batch5]:\n",
    "        labels, imgs = load_data0(ibatch)\n",
    "        x_train_l.append(imgs)\n",
    "        y_train_l.extend(labels)\n",
    "    x_train = np.vstack(x_train_l)\n",
    "    y_train = np.vstack(y_train_l)\n",
    "    \n",
    "    x_test_l = []\n",
    "    y_test_l = []\n",
    "    labels, imgs = load_data0(test_batch)\n",
    "    x_test_l.append(imgs)\n",
    "    y_test_l.extend(labels)\n",
    "    x_test = np.vstack(x_test_l)\n",
    "    y_test = np.vstack(y_test_l)\n",
    "    return (x_train, y_train), (x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17361005",
   "metadata": {},
   "source": [
    "#### Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a84a95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create training and test set\n",
    "(x_train, y_train), (x_test, y_test) = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "466837bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "y_train shape: (50000, 1)\n",
      "x_test shape: (10000, 32, 32, 3)\n",
      "y_test shape: (10000, 1)\n"
     ]
    }
   ],
   "source": [
    "print('x_train shape:', x_train.shape)\n",
    "print('y_train shape:', y_train.shape)\n",
    "print('x_test shape:', x_test.shape)\n",
    "print('y_test shape:', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "529c78cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000 train samples (x)\n",
      "50000 train samples (y)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape[0], 'train samples (x)')\n",
    "print(y_train.shape[0], 'train samples (y)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bfefa9ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 test samples (x)\n",
      "10000 test samples (y)\n"
     ]
    }
   ],
   "source": [
    "print(x_test.shape[0], 'test samples (x)')\n",
    "print(y_test.shape[0], 'test samples (y)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d9dda58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the images\n",
    "X_train = x_train.reshape(x_train.shape[0], -1)\n",
    "X_test = x_test.reshape(x_test.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8bc2396c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data\n",
    "X_train = X_train.astype('float32') / 255\n",
    "X_test = X_test.astype('float32') / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a43cc70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape y_train and y_test to 1d arrays\n",
    "y_train = y_train.ravel()\n",
    "y_test = y_test.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "663edcb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ad3845",
   "metadata": {},
   "source": [
    "#### Define model and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f92c33ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "lr = LogisticRegression(solver='saga', multi_class='multinomial', verbose=1, max_iter=1000, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7f78e83b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, change: 1.00000000\n",
      "Epoch 2, change: 0.31112364\n",
      "Epoch 3, change: 0.17446972\n",
      "Epoch 4, change: 0.13395590\n",
      "Epoch 5, change: 0.10465156\n",
      "Epoch 6, change: 0.08240297\n",
      "Epoch 7, change: 0.07107364\n",
      "Epoch 8, change: 0.06299022\n",
      "Epoch 9, change: 0.05496485\n",
      "Epoch 10, change: 0.04876496\n",
      "Epoch 11, change: 0.04347889\n",
      "Epoch 12, change: 0.03975073\n",
      "Epoch 13, change: 0.03597004\n",
      "Epoch 14, change: 0.03368282\n",
      "Epoch 15, change: 0.03095332\n",
      "Epoch 16, change: 0.02869766\n",
      "Epoch 17, change: 0.02641392\n",
      "Epoch 18, change: 0.02535186\n",
      "Epoch 19, change: 0.02388932\n",
      "Epoch 20, change: 0.02200129\n",
      "Epoch 21, change: 0.02163129\n",
      "Epoch 22, change: 0.02128161\n",
      "Epoch 23, change: 0.02059028\n",
      "Epoch 24, change: 0.01865203\n",
      "Epoch 25, change: 0.01795270\n",
      "Epoch 26, change: 0.01607023\n",
      "Epoch 27, change: 0.01583829\n",
      "Epoch 28, change: 0.01565392\n",
      "Epoch 29, change: 0.01546345\n",
      "Epoch 30, change: 0.01513787\n",
      "Epoch 31, change: 0.01497226\n",
      "Epoch 32, change: 0.01479146\n",
      "Epoch 33, change: 0.01458597\n",
      "Epoch 34, change: 0.01440972\n",
      "Epoch 35, change: 0.01427177\n",
      "Epoch 36, change: 0.01411566\n",
      "Epoch 37, change: 0.01401397\n",
      "Epoch 38, change: 0.01373388\n",
      "Epoch 39, change: 0.01373598\n",
      "Epoch 40, change: 0.01352168\n",
      "Epoch 41, change: 0.01338393\n",
      "Epoch 42, change: 0.01327477\n",
      "Epoch 43, change: 0.01084361\n",
      "Epoch 44, change: 0.00982642\n",
      "Epoch 45, change: 0.00969253\n",
      "Epoch 46, change: 0.00964628\n",
      "Epoch 47, change: 0.00957087\n",
      "Epoch 48, change: 0.00948417\n",
      "Epoch 49, change: 0.00934124\n",
      "Epoch 50, change: 0.00925452\n",
      "Epoch 51, change: 0.00920188\n",
      "Epoch 52, change: 0.00909640\n",
      "Epoch 53, change: 0.00903079\n",
      "Epoch 54, change: 0.00895362\n",
      "Epoch 55, change: 0.00886839\n",
      "Epoch 56, change: 0.00878574\n",
      "Epoch 57, change: 0.00873875\n",
      "Epoch 58, change: 0.00863774\n",
      "Epoch 59, change: 0.00869238\n",
      "Epoch 60, change: 0.00858687\n",
      "Epoch 61, change: 0.00855210\n",
      "Epoch 62, change: 0.00847020\n",
      "Epoch 63, change: 0.00845270\n",
      "Epoch 64, change: 0.00838347\n",
      "Epoch 65, change: 0.00833689\n",
      "Epoch 66, change: 0.00832005\n",
      "Epoch 67, change: 0.00825901\n",
      "Epoch 68, change: 0.00819180\n",
      "Epoch 69, change: 0.00813890\n",
      "Epoch 70, change: 0.00811382\n",
      "Epoch 71, change: 0.00807347\n",
      "Epoch 72, change: 0.00801967\n",
      "Epoch 73, change: 0.00799779\n",
      "Epoch 74, change: 0.00792955\n",
      "Epoch 75, change: 0.00791504\n",
      "Epoch 76, change: 0.00785810\n",
      "Epoch 77, change: 0.00781890\n",
      "Epoch 78, change: 0.00778453\n",
      "Epoch 79, change: 0.00773823\n",
      "Epoch 80, change: 0.00768907\n",
      "Epoch 81, change: 0.00764233\n",
      "Epoch 82, change: 0.00759667\n",
      "Epoch 83, change: 0.00756469\n",
      "Epoch 84, change: 0.00754886\n",
      "Epoch 85, change: 0.00749367\n",
      "Epoch 86, change: 0.00746561\n",
      "Epoch 87, change: 0.00745094\n",
      "Epoch 88, change: 0.00740415\n",
      "Epoch 89, change: 0.00736822\n",
      "Epoch 90, change: 0.00733791\n",
      "Epoch 91, change: 0.00729506\n",
      "Epoch 92, change: 0.00726959\n",
      "Epoch 93, change: 0.00724233\n",
      "Epoch 94, change: 0.00718576\n",
      "Epoch 95, change: 0.00717703\n",
      "Epoch 96, change: 0.00705124\n",
      "Epoch 97, change: 0.00535775\n",
      "Epoch 98, change: 0.00620047\n",
      "Epoch 99, change: 0.00575072\n",
      "Epoch 100, change: 0.00492825\n",
      "Epoch 101, change: 0.00466867\n",
      "Epoch 102, change: 0.00465837\n",
      "Epoch 103, change: 0.00462734\n",
      "Epoch 104, change: 0.00461888\n",
      "Epoch 105, change: 0.00460546\n",
      "Epoch 106, change: 0.00460275\n",
      "Epoch 107, change: 0.00456668\n",
      "Epoch 108, change: 0.00457150\n",
      "Epoch 109, change: 0.00452120\n",
      "Epoch 110, change: 0.00451159\n",
      "Epoch 111, change: 0.00448301\n",
      "Epoch 112, change: 0.00446376\n",
      "Epoch 113, change: 0.00443487\n",
      "Epoch 114, change: 0.00442269\n",
      "Epoch 115, change: 0.00441022\n",
      "Epoch 116, change: 0.00438745\n",
      "Epoch 117, change: 0.00436103\n",
      "Epoch 118, change: 0.00434608\n",
      "Epoch 119, change: 0.00432291\n",
      "Epoch 120, change: 0.00430955\n",
      "Epoch 121, change: 0.00429212\n",
      "Epoch 122, change: 0.00428452\n",
      "Epoch 123, change: 0.00426431\n",
      "Epoch 124, change: 0.00425937\n",
      "Epoch 125, change: 0.00424089\n",
      "Epoch 126, change: 0.00422770\n",
      "Epoch 127, change: 0.00419753\n",
      "Epoch 128, change: 0.00417554\n",
      "Epoch 129, change: 0.00416087\n",
      "Epoch 130, change: 0.00414606\n",
      "Epoch 131, change: 0.00411834\n",
      "Epoch 132, change: 0.00410878\n",
      "Epoch 133, change: 0.00410271\n",
      "Epoch 134, change: 0.00407760\n",
      "Epoch 135, change: 0.00404989\n",
      "Epoch 136, change: 0.00404991\n",
      "Epoch 137, change: 0.00402752\n",
      "Epoch 138, change: 0.00400432\n",
      "Epoch 139, change: 0.00399800\n",
      "Epoch 140, change: 0.00396836\n",
      "Epoch 141, change: 0.00397393\n",
      "Epoch 142, change: 0.00393468\n",
      "Epoch 143, change: 0.00393113\n",
      "Epoch 144, change: 0.00391113\n",
      "Epoch 145, change: 0.00389295\n",
      "Epoch 146, change: 0.00389738\n",
      "Epoch 147, change: 0.00386684\n",
      "Epoch 148, change: 0.00385265\n",
      "Epoch 149, change: 0.00384862\n",
      "Epoch 150, change: 0.00382350\n",
      "Epoch 151, change: 0.00381218\n",
      "Epoch 152, change: 0.00379862\n",
      "Epoch 153, change: 0.00377759\n",
      "Epoch 154, change: 0.00378375\n",
      "Epoch 155, change: 0.00375129\n",
      "Epoch 156, change: 0.00375033\n",
      "Epoch 157, change: 0.00372565\n",
      "Epoch 158, change: 0.00371537\n",
      "Epoch 159, change: 0.00370011\n",
      "Epoch 160, change: 0.00368239\n",
      "Epoch 161, change: 0.00366976\n",
      "Epoch 162, change: 0.00366379\n",
      "Epoch 163, change: 0.00364228\n",
      "Epoch 164, change: 0.00362096\n",
      "Epoch 165, change: 0.00362078\n",
      "Epoch 166, change: 0.00362110\n",
      "Epoch 167, change: 0.00359346\n",
      "Epoch 168, change: 0.00358320\n",
      "Epoch 169, change: 0.00356692\n",
      "Epoch 170, change: 0.00356411\n",
      "Epoch 171, change: 0.00353869\n",
      "Epoch 172, change: 0.00353537\n",
      "Epoch 173, change: 0.00351795\n",
      "Epoch 174, change: 0.00349730\n",
      "Epoch 175, change: 0.00349140\n",
      "Epoch 176, change: 0.00348865\n",
      "Epoch 177, change: 0.00347272\n",
      "Epoch 178, change: 0.00344886\n",
      "Epoch 179, change: 0.00344399\n",
      "Epoch 180, change: 0.00343319\n",
      "Epoch 181, change: 0.00342618\n",
      "Epoch 182, change: 0.00340448\n",
      "Epoch 183, change: 0.00340712\n",
      "Epoch 184, change: 0.00338400\n",
      "Epoch 185, change: 0.00336853\n",
      "Epoch 186, change: 0.00336046\n",
      "Epoch 187, change: 0.00335725\n",
      "Epoch 188, change: 0.00333493\n",
      "Epoch 189, change: 0.00333823\n",
      "Epoch 190, change: 0.00332182\n",
      "Epoch 191, change: 0.00330513\n",
      "Epoch 192, change: 0.00329214\n",
      "Epoch 193, change: 0.00328733\n",
      "Epoch 194, change: 0.00327466\n",
      "Epoch 195, change: 0.00326756\n",
      "Epoch 196, change: 0.00324804\n",
      "Epoch 197, change: 0.00324450\n",
      "Epoch 198, change: 0.00323318\n",
      "Epoch 199, change: 0.00321265\n",
      "Epoch 200, change: 0.00321289\n",
      "Epoch 201, change: 0.00319917\n",
      "Epoch 202, change: 0.00319759\n",
      "Epoch 203, change: 0.00317904\n",
      "Epoch 204, change: 0.00316619\n",
      "Epoch 205, change: 0.00316073\n",
      "Epoch 206, change: 0.00315321\n",
      "Epoch 207, change: 0.00313662\n",
      "Epoch 208, change: 0.00312802\n",
      "Epoch 209, change: 0.00311834\n",
      "Epoch 210, change: 0.00311291\n",
      "Epoch 211, change: 0.00310606\n",
      "Epoch 212, change: 0.00308611\n",
      "Epoch 213, change: 0.00308659\n",
      "Epoch 214, change: 0.00306932\n",
      "Epoch 215, change: 0.00306716\n",
      "Epoch 216, change: 0.00305489\n",
      "Epoch 217, change: 0.00304344\n",
      "Epoch 218, change: 0.00303197\n",
      "Epoch 219, change: 0.00303247\n",
      "Epoch 220, change: 0.00302720\n",
      "Epoch 221, change: 0.00302247\n",
      "Epoch 222, change: 0.00301566\n",
      "Epoch 223, change: 0.00300775\n",
      "Epoch 224, change: 0.00301121\n",
      "Epoch 225, change: 0.00299277\n",
      "Epoch 226, change: 0.00299339\n",
      "Epoch 227, change: 0.00299182\n",
      "Epoch 228, change: 0.00298343\n",
      "Epoch 229, change: 0.00298234\n",
      "Epoch 230, change: 0.00296846\n",
      "Epoch 231, change: 0.00296750\n",
      "Epoch 232, change: 0.00297102\n",
      "Epoch 233, change: 0.00296175\n",
      "Epoch 234, change: 0.00296209\n",
      "Epoch 235, change: 0.00295101\n",
      "Epoch 236, change: 0.00293814\n",
      "Epoch 237, change: 0.00294865\n",
      "Epoch 238, change: 0.00293578\n",
      "Epoch 239, change: 0.00293766\n",
      "Epoch 240, change: 0.00292690\n",
      "Epoch 241, change: 0.00291075\n",
      "Epoch 242, change: 0.00290674\n",
      "Epoch 243, change: 0.00290138\n",
      "Epoch 244, change: 0.00289413\n",
      "Epoch 245, change: 0.00287969\n",
      "Epoch 246, change: 0.00287256\n",
      "Epoch 247, change: 0.00286673\n",
      "Epoch 248, change: 0.00285579\n",
      "Epoch 249, change: 0.00284928\n",
      "Epoch 250, change: 0.00284070\n",
      "Epoch 251, change: 0.00283307\n",
      "Epoch 252, change: 0.00282159\n",
      "Epoch 253, change: 0.00282031\n",
      "Epoch 254, change: 0.00280657\n",
      "Epoch 255, change: 0.00280155\n",
      "Epoch 256, change: 0.00279448\n",
      "Epoch 257, change: 0.00278758\n",
      "Epoch 258, change: 0.00277935\n",
      "Epoch 259, change: 0.00277420\n",
      "Epoch 260, change: 0.00275748\n",
      "Epoch 261, change: 0.00275552\n",
      "Epoch 262, change: 0.00274883\n",
      "Epoch 263, change: 0.00273772\n",
      "Epoch 264, change: 0.00273119\n",
      "Epoch 265, change: 0.00272985\n",
      "Epoch 266, change: 0.00271279\n",
      "Epoch 267, change: 0.00270759\n",
      "Epoch 268, change: 0.00269595\n",
      "Epoch 269, change: 0.00269727\n",
      "Epoch 270, change: 0.00268597\n",
      "Epoch 271, change: 0.00267582\n",
      "Epoch 272, change: 0.00267322\n",
      "Epoch 273, change: 0.00265920\n",
      "Epoch 274, change: 0.00265300\n",
      "Epoch 275, change: 0.00265128\n",
      "Epoch 276, change: 0.00265039\n",
      "Epoch 277, change: 0.00263338\n",
      "Epoch 278, change: 0.00262368\n",
      "Epoch 279, change: 0.00261972\n",
      "Epoch 280, change: 0.00261417\n",
      "Epoch 281, change: 0.00260349\n",
      "Epoch 282, change: 0.00259404\n",
      "Epoch 283, change: 0.00258989\n",
      "Epoch 284, change: 0.00258671\n",
      "Epoch 285, change: 0.00257762\n",
      "Epoch 286, change: 0.00257144\n",
      "Epoch 287, change: 0.00255908\n",
      "Epoch 288, change: 0.00255388\n",
      "Epoch 289, change: 0.00254498\n",
      "Epoch 290, change: 0.00254688\n",
      "Epoch 291, change: 0.00253508\n",
      "Epoch 292, change: 0.00253363\n",
      "Epoch 293, change: 0.00252212\n",
      "Epoch 294, change: 0.00251260\n",
      "Epoch 295, change: 0.00250960\n",
      "Epoch 296, change: 0.00250028\n",
      "Epoch 297, change: 0.00249664\n",
      "Epoch 298, change: 0.00249363\n",
      "Epoch 299, change: 0.00247968\n",
      "Epoch 300, change: 0.00247410\n",
      "Epoch 301, change: 0.00247454\n",
      "Epoch 302, change: 0.00245911\n",
      "Epoch 303, change: 0.00245824\n",
      "Epoch 304, change: 0.00245009\n",
      "Epoch 305, change: 0.00244622\n",
      "Epoch 306, change: 0.00243742\n",
      "Epoch 307, change: 0.00243192\n",
      "Epoch 308, change: 0.00243095\n",
      "Epoch 309, change: 0.00241612\n",
      "Epoch 310, change: 0.00241648\n",
      "Epoch 311, change: 0.00240809\n",
      "Epoch 312, change: 0.00240041\n",
      "Epoch 313, change: 0.00239995\n",
      "Epoch 314, change: 0.00239938\n",
      "Epoch 315, change: 0.00240401\n",
      "Epoch 316, change: 0.00239655\n",
      "Epoch 317, change: 0.00239763\n",
      "Epoch 318, change: 0.00240084\n",
      "Epoch 319, change: 0.00239959\n",
      "Epoch 320, change: 0.00240306\n",
      "Epoch 321, change: 0.00239647\n",
      "Epoch 322, change: 0.00239649\n",
      "Epoch 323, change: 0.00239840\n",
      "Epoch 324, change: 0.00239263\n",
      "Epoch 325, change: 0.00239571\n",
      "Epoch 326, change: 0.00239088\n",
      "Epoch 327, change: 0.00239209\n",
      "Epoch 328, change: 0.00238614\n",
      "Epoch 329, change: 0.00239612\n",
      "Epoch 330, change: 0.00239518\n",
      "Epoch 331, change: 0.00238822\n",
      "Epoch 332, change: 0.00238740\n",
      "Epoch 333, change: 0.00239265\n",
      "Epoch 334, change: 0.00238695\n",
      "Epoch 335, change: 0.00239166\n",
      "Epoch 336, change: 0.00239591\n",
      "Epoch 337, change: 0.00239093\n",
      "Epoch 338, change: 0.00238712\n",
      "Epoch 339, change: 0.00237112\n",
      "Epoch 340, change: 0.00238027\n",
      "Epoch 341, change: 0.00240292\n",
      "Epoch 342, change: 0.00239605\n",
      "Epoch 343, change: 0.00239930\n",
      "Epoch 344, change: 0.00240023\n",
      "Epoch 345, change: 0.00239359\n",
      "Epoch 346, change: 0.00239700\n",
      "Epoch 347, change: 0.00239776\n",
      "Epoch 348, change: 0.00239107\n",
      "Epoch 349, change: 0.00238407\n",
      "Epoch 350, change: 0.00239163\n",
      "Epoch 351, change: 0.00238624\n",
      "Epoch 352, change: 0.00239050\n",
      "Epoch 353, change: 0.00238446\n",
      "Epoch 354, change: 0.00238628\n",
      "Epoch 355, change: 0.00238517\n",
      "Epoch 356, change: 0.00237968\n",
      "Epoch 357, change: 0.00236870\n",
      "Epoch 358, change: 0.00237131\n",
      "Epoch 359, change: 0.00237415\n",
      "Epoch 360, change: 0.00237323\n",
      "Epoch 361, change: 0.00237136\n",
      "Epoch 362, change: 0.00238742\n",
      "Epoch 363, change: 0.00237525\n",
      "Epoch 364, change: 0.00237183\n",
      "Epoch 365, change: 0.00236979\n",
      "Epoch 366, change: 0.00237607\n",
      "Epoch 367, change: 0.00237213\n",
      "Epoch 368, change: 0.00238169\n",
      "Epoch 369, change: 0.00237275\n",
      "Epoch 370, change: 0.00237446\n",
      "Epoch 371, change: 0.00237473\n",
      "Epoch 372, change: 0.00237662\n",
      "Epoch 373, change: 0.00237774\n",
      "Epoch 374, change: 0.00237725\n",
      "Epoch 375, change: 0.00237908\n",
      "Epoch 376, change: 0.00237704\n",
      "Epoch 377, change: 0.00237470\n",
      "Epoch 378, change: 0.00237397\n",
      "Epoch 379, change: 0.00237163\n",
      "Epoch 380, change: 0.00237745\n",
      "Epoch 381, change: 0.00237517\n",
      "Epoch 382, change: 0.00237545\n",
      "Epoch 383, change: 0.00238008\n",
      "Epoch 384, change: 0.00237000\n",
      "Epoch 385, change: 0.00237512\n",
      "Epoch 386, change: 0.00237266\n",
      "Epoch 387, change: 0.00236870\n",
      "Epoch 388, change: 0.00237936\n",
      "Epoch 389, change: 0.00222678\n",
      "Epoch 390, change: 0.00217650\n",
      "Epoch 391, change: 0.00172520\n",
      "Epoch 392, change: 0.00160622\n",
      "Epoch 393, change: 0.00189626\n",
      "Epoch 394, change: 0.00201284\n",
      "Epoch 395, change: 0.00221536\n",
      "Epoch 396, change: 0.00211227\n",
      "Epoch 397, change: 0.00198514\n",
      "Epoch 398, change: 0.00226736\n",
      "Epoch 399, change: 0.00202234\n",
      "Epoch 400, change: 0.00238240\n",
      "Epoch 401, change: 0.00208670\n",
      "Epoch 402, change: 0.00202490\n",
      "Epoch 403, change: 0.00204573\n",
      "Epoch 404, change: 0.00238281\n",
      "Epoch 405, change: 0.00228283\n",
      "Epoch 406, change: 0.00182684\n",
      "Epoch 407, change: 0.00231843\n",
      "Epoch 408, change: 0.00172930\n",
      "Epoch 409, change: 0.00186291\n",
      "Epoch 410, change: 0.00147470\n",
      "Epoch 411, change: 0.00174597\n",
      "Epoch 412, change: 0.00217184\n",
      "Epoch 413, change: 0.00236824\n",
      "Epoch 414, change: 0.00175077\n",
      "Epoch 415, change: 0.00131492\n",
      "Epoch 416, change: 0.00157649\n",
      "Epoch 417, change: 0.00131087\n",
      "Epoch 418, change: 0.00167438\n",
      "Epoch 419, change: 0.00166562\n",
      "Epoch 420, change: 0.00136874\n",
      "Epoch 421, change: 0.00142823\n",
      "Epoch 422, change: 0.00146169\n",
      "Epoch 423, change: 0.00134029\n",
      "Epoch 424, change: 0.00127628\n",
      "Epoch 425, change: 0.00128050\n",
      "Epoch 426, change: 0.00119431\n",
      "Epoch 427, change: 0.00125811\n",
      "Epoch 428, change: 0.00125162\n",
      "Epoch 429, change: 0.00143894\n",
      "Epoch 430, change: 0.00121691\n",
      "Epoch 431, change: 0.00150610\n",
      "Epoch 432, change: 0.00120916\n",
      "Epoch 433, change: 0.00161309\n",
      "Epoch 434, change: 0.00137820\n",
      "Epoch 435, change: 0.00119570\n",
      "Epoch 436, change: 0.00130914\n",
      "Epoch 437, change: 0.00134212\n",
      "Epoch 438, change: 0.00131807\n",
      "Epoch 439, change: 0.00131349\n",
      "Epoch 440, change: 0.00180832\n",
      "Epoch 441, change: 0.00237167\n",
      "Epoch 442, change: 0.00237644\n",
      "Epoch 443, change: 0.00237883\n",
      "Epoch 444, change: 0.00237366\n",
      "Epoch 445, change: 0.00236748\n",
      "Epoch 446, change: 0.00236945\n",
      "Epoch 447, change: 0.00236474\n",
      "Epoch 448, change: 0.00236432\n",
      "Epoch 449, change: 0.00236277\n",
      "Epoch 450, change: 0.00183380\n",
      "Epoch 451, change: 0.00146719\n",
      "Epoch 452, change: 0.00119511\n",
      "Epoch 453, change: 0.00119434\n",
      "Epoch 454, change: 0.00119386\n",
      "Epoch 455, change: 0.00119315\n",
      "Epoch 456, change: 0.00126528\n",
      "Epoch 457, change: 0.00119428\n",
      "Epoch 458, change: 0.00128678\n",
      "Epoch 459, change: 0.00119341\n",
      "Epoch 460, change: 0.00120014\n",
      "Epoch 461, change: 0.00119374\n",
      "Epoch 462, change: 0.00119409\n",
      "Epoch 463, change: 0.00119297\n",
      "Epoch 464, change: 0.00119400\n",
      "Epoch 465, change: 0.00119347\n",
      "Epoch 466, change: 0.00119466\n",
      "Epoch 467, change: 0.00122705\n",
      "Epoch 468, change: 0.00119341\n",
      "Epoch 469, change: 0.00154775\n",
      "Epoch 470, change: 0.00119240\n",
      "Epoch 471, change: 0.00125598\n",
      "Epoch 472, change: 0.00119210\n",
      "Epoch 473, change: 0.00143872\n",
      "Epoch 474, change: 0.00119225\n",
      "Epoch 475, change: 0.00122610\n",
      "Epoch 476, change: 0.00119246\n",
      "Epoch 477, change: 0.00119255\n",
      "Epoch 478, change: 0.00119431\n",
      "Epoch 479, change: 0.00119378\n",
      "Epoch 480, change: 0.00119395\n",
      "Epoch 481, change: 0.00119178\n",
      "Epoch 482, change: 0.00119363\n",
      "Epoch 483, change: 0.00119404\n",
      "Epoch 484, change: 0.00119214\n",
      "Epoch 485, change: 0.00119226\n",
      "Epoch 486, change: 0.00119086\n",
      "Epoch 487, change: 0.00119481\n",
      "Epoch 488, change: 0.00119401\n",
      "Epoch 489, change: 0.00122390\n",
      "Epoch 490, change: 0.00119228\n",
      "Epoch 491, change: 0.00119255\n",
      "Epoch 492, change: 0.00119371\n",
      "Epoch 493, change: 0.00119112\n",
      "Epoch 494, change: 0.00119190\n",
      "Epoch 495, change: 0.00119217\n",
      "Epoch 496, change: 0.00132591\n",
      "Epoch 497, change: 0.00119128\n",
      "Epoch 498, change: 0.00134031\n",
      "Epoch 499, change: 0.00119476\n",
      "Epoch 500, change: 0.00139087\n",
      "Epoch 501, change: 0.00143314\n",
      "Epoch 502, change: 0.00127166\n",
      "Epoch 503, change: 0.00128441\n",
      "Epoch 504, change: 0.00119309\n",
      "Epoch 505, change: 0.00130530\n",
      "Epoch 506, change: 0.00140873\n",
      "Epoch 507, change: 0.00154390\n",
      "Epoch 508, change: 0.00129209\n",
      "Epoch 509, change: 0.00125857\n",
      "Epoch 510, change: 0.00128727\n",
      "Epoch 511, change: 0.00146484\n",
      "Epoch 512, change: 0.00144715\n",
      "Epoch 513, change: 0.00150014\n",
      "Epoch 514, change: 0.00135295\n",
      "Epoch 515, change: 0.00119341\n",
      "Epoch 516, change: 0.00145061\n",
      "Epoch 517, change: 0.00119237\n",
      "Epoch 518, change: 0.00126799\n",
      "Epoch 519, change: 0.00140673\n",
      "Epoch 520, change: 0.00119249\n",
      "Epoch 521, change: 0.00128651\n",
      "Epoch 522, change: 0.00131331\n",
      "Epoch 523, change: 0.00119235\n",
      "Epoch 524, change: 0.00119426\n",
      "Epoch 525, change: 0.00148332\n",
      "Epoch 526, change: 0.00119262\n",
      "Epoch 527, change: 0.00119214\n",
      "Epoch 528, change: 0.00119241\n",
      "Epoch 529, change: 0.00119131\n",
      "Epoch 530, change: 0.00119223\n",
      "Epoch 531, change: 0.00119152\n",
      "Epoch 532, change: 0.00119212\n",
      "Epoch 533, change: 0.00119197\n",
      "Epoch 534, change: 0.00119110\n",
      "Epoch 535, change: 0.00119164\n",
      "Epoch 536, change: 0.00119134\n",
      "Epoch 537, change: 0.00119453\n",
      "Epoch 538, change: 0.00118896\n",
      "Epoch 539, change: 0.00119143\n",
      "Epoch 540, change: 0.00124383\n",
      "Epoch 541, change: 0.00119126\n",
      "Epoch 542, change: 0.00119099\n",
      "Epoch 543, change: 0.00119328\n",
      "Epoch 544, change: 0.00119152\n",
      "Epoch 545, change: 0.00119215\n",
      "Epoch 546, change: 0.00118962\n",
      "Epoch 547, change: 0.00119132\n",
      "Epoch 548, change: 0.00119129\n",
      "Epoch 549, change: 0.00118992\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 550, change: 0.0max_iter reached after 3547 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shrivastavasatyam/miniconda3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed: 59.1min finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=1000, multi_class=&#x27;multinomial&#x27;, n_jobs=-1,\n",
       "                   solver=&#x27;saga&#x27;, verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000, multi_class=&#x27;multinomial&#x27;, n_jobs=-1,\n",
       "                   solver=&#x27;saga&#x27;, verbose=1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=1000, multi_class='multinomial', n_jobs=-1,\n",
       "                   solver='saga', verbose=1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38a9162",
   "metadata": {},
   "source": [
    "#### Save and load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0fba3bd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['logistic_regression_model_saga.sav']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the model to a file\n",
    "joblib.dump(lr, 'logistic_regression_model_saga.sav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7990cea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved model from a file\n",
    "loaded_model = joblib.load('logistic_regression_model_saga.sav')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d623ac1",
   "metadata": {},
   "source": [
    "#### Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bfcf352e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.5047\n",
      "Val Accuracy: 0.3848\n",
      "Test Accuracy: 0.3864\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "train_acc = accuracy_score(y_train, loaded_model.predict(X_train))\n",
    "val_acc = accuracy_score(y_val, loaded_model.predict(X_val))\n",
    "test_acc = accuracy_score(y_test, loaded_model.predict(X_test))\n",
    "\n",
    "print(f\"Train Accuracy: {train_acc:.4f}\")\n",
    "print(f\"Val Accuracy: {val_acc:.4f}\")\n",
    "print(f\"Test Accuracy: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b4b6eea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Precision: 0.3833\n",
      "Test Recall: 0.3864\n",
      "Test F1 score: 0.3843\n"
     ]
    }
   ],
   "source": [
    "# Calculate precision, recall, and F1 score on test set\n",
    "test_pred = loaded_model.predict(X_test)\n",
    "precision = precision_score(y_test, test_pred, average='weighted')\n",
    "recall = recall_score(y_test, test_pred, average='weighted')\n",
    "f1 = f1_score(y_test, test_pred, average='weighted')\n",
    "\n",
    "print(f\"Test Precision: {precision:.4f}\")\n",
    "print(f\"Test Recall: {recall:.4f}\")\n",
    "print(f\"Test F1 score: {f1:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
