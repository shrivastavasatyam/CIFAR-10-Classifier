{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd0e9394",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import library dependencies\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2554fc6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on Macbook Metal GPU!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='mps')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if GPU is available\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print('Training on GPU!')\n",
    "    device = torch.device('cuda')\n",
    "elif torch.has_mps:\n",
    "    print('Training on Macbook Metal GPU!')\n",
    "    device = torch.device('mps')\n",
    "else:\n",
    "    print('No GPU available. Training on CPU!')\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1711775b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_PATH='../'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5df3d530",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35b90acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c11a8b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_dataset = CIFAR10(root=ROOT_PATH, download=True, train=True, transform=transform)\n",
    "eval_dataset = CIFAR10(root=ROOT_PATH, train=False, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3abaa9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_loader = DataLoader(dataset=train_dataset, num_workers=4, batch_size=BATCH_SIZE, shuffle=True)\n",
    "eval_data_loader = DataLoader(dataset=eval_dataset, num_workers=4, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b3651f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, planes, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = nn.functional.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = nn.functional.relu(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae62ad94",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = 64\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.layer1 = nn.Sequential(\n",
    "            BasicBlock(64, 64, stride=1),\n",
    "            BasicBlock(64, 64, stride=1)\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            BasicBlock(64, 128, stride=2),\n",
    "            BasicBlock(128, 128, stride=1)\n",
    "        )\n",
    "        self.layer3 = nn.Sequential(\n",
    "            BasicBlock(128, 256, stride=2),\n",
    "            BasicBlock(256, 256, stride=1)\n",
    "        )\n",
    "        self.layer4 = nn.Sequential(\n",
    "            BasicBlock(256, 512, stride=2),\n",
    "            BasicBlock(512, 512, stride=1)\n",
    "        )\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.linear = nn.Linear(512, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = nn.functional.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = self.avgpool(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e4a7f655",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (linear): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create an instance of the ResNet class\n",
    "net = ResNet()\n",
    "net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ef2f4090",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eff55a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede8627e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  1000] loss: 2.102\n",
      "[1,  2000] loss: 1.806\n",
      "[1,  3000] loss: 1.663\n",
      "[1,  4000] loss: 1.542\n",
      "[1,  5000] loss: 1.433\n",
      "[1,  6000] loss: 1.340\n",
      "[1,  7000] loss: 1.289\n",
      "[1,  8000] loss: 1.189\n",
      "[1,  9000] loss: 1.137\n",
      "[1, 10000] loss: 1.072\n",
      "[1, 11000] loss: 1.065\n",
      "[1, 12000] loss: 1.008\n",
      "[2,  1000] loss: 0.918\n",
      "[2,  2000] loss: 0.893\n",
      "[2,  3000] loss: 0.869\n",
      "[2,  4000] loss: 0.860\n",
      "[2,  5000] loss: 0.834\n",
      "[2,  6000] loss: 0.827\n",
      "[2,  7000] loss: 0.785\n",
      "[2,  8000] loss: 0.763\n",
      "[2,  9000] loss: 0.785\n",
      "[2, 10000] loss: 0.775\n",
      "[2, 11000] loss: 0.770\n",
      "[2, 12000] loss: 0.733\n",
      "[3,  1000] loss: 0.586\n",
      "[3,  2000] loss: 0.598\n",
      "[3,  3000] loss: 0.623\n",
      "[3,  4000] loss: 0.611\n",
      "[3,  5000] loss: 0.594\n",
      "[3,  6000] loss: 0.616\n",
      "[3,  7000] loss: 0.607\n",
      "[3,  8000] loss: 0.589\n",
      "[3,  9000] loss: 0.642\n",
      "[3, 10000] loss: 0.566\n",
      "[3, 11000] loss: 0.562\n",
      "[3, 12000] loss: 0.576\n",
      "[4,  1000] loss: 0.444\n",
      "[4,  2000] loss: 0.444\n",
      "[4,  3000] loss: 0.439\n",
      "[4,  4000] loss: 0.461\n",
      "[4,  5000] loss: 0.449\n",
      "[4,  6000] loss: 0.462\n",
      "[4,  7000] loss: 0.477\n",
      "[4,  8000] loss: 0.473\n",
      "[4,  9000] loss: 0.460\n",
      "[4, 10000] loss: 0.471\n",
      "[4, 11000] loss: 0.454\n",
      "[4, 12000] loss: 0.475\n",
      "[5,  1000] loss: 0.312\n",
      "[5,  2000] loss: 0.337\n",
      "[5,  3000] loss: 0.322\n",
      "[5,  4000] loss: 0.351\n",
      "[5,  5000] loss: 0.362\n",
      "[5,  6000] loss: 0.326\n",
      "[5,  7000] loss: 0.339\n",
      "[5,  8000] loss: 0.353\n",
      "[5,  9000] loss: 0.330\n",
      "[5, 10000] loss: 0.361\n",
      "[5, 11000] loss: 0.363\n",
      "[5, 12000] loss: 0.382\n",
      "[6,  1000] loss: 0.226\n",
      "[6,  2000] loss: 0.230\n",
      "[6,  3000] loss: 0.230\n",
      "[6,  4000] loss: 0.247\n",
      "[6,  5000] loss: 0.256\n",
      "[6,  6000] loss: 0.258\n",
      "[6,  7000] loss: 0.265\n",
      "[6,  8000] loss: 0.284\n",
      "[6,  9000] loss: 0.268\n",
      "[6, 10000] loss: 0.275\n",
      "[6, 11000] loss: 0.273\n",
      "[6, 12000] loss: 0.259\n",
      "[7,  1000] loss: 0.157\n",
      "[7,  2000] loss: 0.150\n",
      "[7,  3000] loss: 0.161\n",
      "[7,  4000] loss: 0.164\n",
      "[7,  5000] loss: 0.160\n",
      "[7,  6000] loss: 0.173\n",
      "[7,  7000] loss: 0.187\n",
      "[7,  8000] loss: 0.194\n",
      "[7,  9000] loss: 0.195\n",
      "[7, 10000] loss: 0.190\n",
      "[7, 11000] loss: 0.195\n",
      "[7, 12000] loss: 0.210\n",
      "[8,  1000] loss: 0.109\n",
      "[8,  2000] loss: 0.097\n",
      "[8,  3000] loss: 0.099\n",
      "[8,  4000] loss: 0.111\n",
      "[8,  5000] loss: 0.112\n",
      "[8,  6000] loss: 0.122\n",
      "[8,  7000] loss: 0.132\n",
      "[8,  8000] loss: 0.129\n",
      "[8,  9000] loss: 0.121\n",
      "[8, 10000] loss: 0.131\n",
      "[8, 11000] loss: 0.134\n",
      "[8, 12000] loss: 0.146\n",
      "[9,  1000] loss: 0.071\n",
      "[9,  2000] loss: 0.072\n",
      "[9,  3000] loss: 0.064\n",
      "[9,  4000] loss: 0.079\n",
      "[9,  5000] loss: 0.081\n",
      "[9,  6000] loss: 0.102\n",
      "[9,  7000] loss: 0.097\n",
      "[9,  8000] loss: 0.090\n",
      "[9,  9000] loss: 0.079\n",
      "[9, 10000] loss: 0.105\n",
      "[9, 11000] loss: 0.081\n",
      "[9, 12000] loss: 0.089\n",
      "[10,  1000] loss: 0.057\n",
      "[10,  2000] loss: 0.060\n",
      "[10,  3000] loss: 0.051\n",
      "[10,  4000] loss: 0.049\n",
      "[10,  5000] loss: 0.063\n",
      "[10,  6000] loss: 0.055\n",
      "[10,  7000] loss: 0.056\n",
      "[10,  8000] loss: 0.072\n",
      "[10,  9000] loss: 0.070\n",
      "[10, 10000] loss: 0.070\n",
      "[10, 11000] loss: 0.058\n",
      "[10, 12000] loss: 0.055\n",
      "[11,  1000] loss: 0.047\n",
      "[11,  2000] loss: 0.032\n",
      "[11,  3000] loss: 0.035\n",
      "[11,  4000] loss: 0.037\n",
      "[11,  5000] loss: 0.043\n",
      "[11,  6000] loss: 0.049\n",
      "[11,  7000] loss: 0.056\n",
      "[11,  8000] loss: 0.055\n",
      "[11,  9000] loss: 0.052\n",
      "[11, 10000] loss: 0.060\n",
      "[11, 11000] loss: 0.059\n",
      "[11, 12000] loss: 0.053\n",
      "[12,  1000] loss: 0.038\n",
      "[12,  2000] loss: 0.035\n",
      "[12,  3000] loss: 0.032\n",
      "[12,  4000] loss: 0.039\n",
      "[12,  5000] loss: 0.034\n",
      "[12,  6000] loss: 0.030\n",
      "[12,  7000] loss: 0.034\n",
      "[12,  8000] loss: 0.037\n",
      "[12,  9000] loss: 0.038\n",
      "[12, 10000] loss: 0.049\n",
      "[12, 11000] loss: 0.045\n",
      "[12, 12000] loss: 0.043\n",
      "[13,  1000] loss: 0.023\n",
      "[13,  2000] loss: 0.019\n",
      "[13,  3000] loss: 0.020\n",
      "[13,  4000] loss: 0.026\n",
      "[13,  5000] loss: 0.026\n",
      "[13,  6000] loss: 0.032\n",
      "[13,  7000] loss: 0.025\n",
      "[13,  8000] loss: 0.018\n",
      "[13,  9000] loss: 0.022\n",
      "[13, 10000] loss: 0.023\n",
      "[13, 11000] loss: 0.028\n",
      "[13, 12000] loss: 0.026\n",
      "[14,  1000] loss: 0.016\n",
      "[14,  2000] loss: 0.015\n",
      "[14,  3000] loss: 0.017\n",
      "[14,  4000] loss: 0.014\n",
      "[14,  5000] loss: 0.019\n",
      "[14,  6000] loss: 0.018\n",
      "[14,  7000] loss: 0.013\n",
      "[14,  8000] loss: 0.013\n",
      "[14,  9000] loss: 0.018\n",
      "[14, 10000] loss: 0.018\n",
      "[14, 11000] loss: 0.024\n",
      "[14, 12000] loss: 0.023\n",
      "[15,  1000] loss: 0.016\n",
      "[15,  2000] loss: 0.013\n",
      "[15,  3000] loss: 0.011\n",
      "[15,  4000] loss: 0.011\n",
      "[15,  5000] loss: 0.011\n",
      "[15,  6000] loss: 0.015\n",
      "[15,  7000] loss: 0.010\n",
      "[15,  8000] loss: 0.010\n",
      "[15,  9000] loss: 0.013\n",
      "[15, 10000] loss: 0.013\n",
      "[15, 11000] loss: 0.011\n",
      "[15, 12000] loss: 0.013\n",
      "[16,  1000] loss: 0.012\n",
      "[16,  2000] loss: 0.011\n",
      "[16,  3000] loss: 0.010\n",
      "[16,  4000] loss: 0.013\n",
      "[16,  5000] loss: 0.007\n",
      "[16,  6000] loss: 0.010\n",
      "[16,  7000] loss: 0.007\n",
      "[16,  8000] loss: 0.013\n",
      "[16,  9000] loss: 0.013\n",
      "[16, 10000] loss: 0.015\n",
      "[16, 11000] loss: 0.020\n",
      "[16, 12000] loss: 0.013\n",
      "[17,  1000] loss: 0.005\n",
      "[17,  2000] loss: 0.004\n",
      "[17,  3000] loss: 0.008\n",
      "[17,  4000] loss: 0.006\n",
      "[17,  5000] loss: 0.009\n",
      "[17,  6000] loss: 0.009\n",
      "[17,  7000] loss: 0.009\n",
      "[17,  8000] loss: 0.005\n",
      "[17,  9000] loss: 0.004\n",
      "[17, 10000] loss: 0.005\n",
      "[17, 11000] loss: 0.009\n",
      "[17, 12000] loss: 0.006\n",
      "[18,  1000] loss: 0.006\n",
      "[18,  2000] loss: 0.004\n",
      "[18,  3000] loss: 0.005\n",
      "[18,  4000] loss: 0.006\n",
      "[18,  5000] loss: 0.006\n",
      "[18,  6000] loss: 0.007\n",
      "[18,  7000] loss: 0.007\n",
      "[18,  8000] loss: 0.005\n",
      "[18,  9000] loss: 0.007\n",
      "[18, 10000] loss: 0.007\n",
      "[18, 11000] loss: 0.008\n",
      "[18, 12000] loss: 0.005\n",
      "[19,  1000] loss: 0.005\n",
      "[19,  2000] loss: 0.004\n",
      "[19,  3000] loss: 0.005\n",
      "[19,  4000] loss: 0.006\n",
      "[19,  5000] loss: 0.004\n",
      "[19,  6000] loss: 0.006\n",
      "[19,  7000] loss: 0.004\n",
      "[19,  8000] loss: 0.002\n",
      "[19,  9000] loss: 0.003\n",
      "[19, 10000] loss: 0.002\n",
      "[19, 11000] loss: 0.005\n",
      "[19, 12000] loss: 0.004\n",
      "[20,  1000] loss: 0.003\n",
      "[20,  2000] loss: 0.004\n",
      "[20,  3000] loss: 0.003\n",
      "[20,  4000] loss: 0.003\n",
      "[20,  5000] loss: 0.003\n",
      "[20,  6000] loss: 0.007\n",
      "[20,  7000] loss: 0.005\n",
      "[20,  8000] loss: 0.004\n",
      "[20,  9000] loss: 0.002\n",
      "[20, 10000] loss: 0.004\n",
      "[20, 11000] loss: 0.003\n",
      "[20, 12000] loss: 0.005\n",
      "[21,  1000] loss: 0.003\n",
      "[21,  2000] loss: 0.003\n",
      "[21,  3000] loss: 0.002\n",
      "[21,  4000] loss: 0.002\n",
      "[21,  5000] loss: 0.002\n",
      "[21,  6000] loss: 0.002\n",
      "[21,  7000] loss: 0.001\n",
      "[21,  8000] loss: 0.001\n",
      "[21,  9000] loss: 0.002\n",
      "[21, 10000] loss: 0.002\n",
      "[21, 11000] loss: 0.002\n",
      "[21, 12000] loss: 0.002\n",
      "[22,  1000] loss: 0.002\n",
      "[22,  2000] loss: 0.002\n",
      "[22,  3000] loss: 0.001\n",
      "[22,  4000] loss: 0.002\n",
      "[22,  5000] loss: 0.004\n",
      "[22,  6000] loss: 0.006\n",
      "[22,  7000] loss: 0.003\n",
      "[22,  8000] loss: 0.002\n",
      "[22,  9000] loss: 0.004\n",
      "[22, 10000] loss: 0.005\n",
      "[22, 11000] loss: 0.003\n",
      "[22, 12000] loss: 0.004\n",
      "[23,  1000] loss: 0.003\n",
      "[23,  2000] loss: 0.002\n",
      "[23,  3000] loss: 0.003\n",
      "[23,  4000] loss: 0.006\n",
      "[23,  5000] loss: 0.003\n",
      "[23,  6000] loss: 0.002\n",
      "[23,  7000] loss: 0.004\n",
      "[23,  8000] loss: 0.003\n",
      "[23,  9000] loss: 0.003\n",
      "[23, 10000] loss: 0.002\n",
      "[23, 11000] loss: 0.002\n",
      "[23, 12000] loss: 0.002\n",
      "[24,  1000] loss: 0.001\n",
      "[24,  2000] loss: 0.001\n",
      "[24,  3000] loss: 0.001\n",
      "[24,  4000] loss: 0.001\n",
      "[24,  5000] loss: 0.001\n",
      "[24,  6000] loss: 0.001\n",
      "[24,  7000] loss: 0.001\n",
      "[24,  8000] loss: 0.001\n",
      "[24,  9000] loss: 0.002\n",
      "[24, 10000] loss: 0.001\n",
      "[24, 11000] loss: 0.002\n",
      "[24, 12000] loss: 0.001\n",
      "[25,  1000] loss: 0.001\n",
      "[25,  2000] loss: 0.002\n",
      "[25,  3000] loss: 0.001\n",
      "[25,  4000] loss: 0.001\n",
      "[25,  5000] loss: 0.002\n",
      "[25,  6000] loss: 0.001\n",
      "[25,  7000] loss: 0.001\n",
      "[25,  8000] loss: 0.001\n",
      "[25,  9000] loss: 0.001\n",
      "[25, 10000] loss: 0.001\n",
      "[25, 11000] loss: 0.001\n",
      "[25, 12000] loss: 0.001\n",
      "[26,  1000] loss: 0.001\n",
      "[26,  2000] loss: 0.000\n",
      "[26,  3000] loss: 0.001\n",
      "[26,  4000] loss: 0.001\n",
      "[26,  5000] loss: 0.001\n",
      "[26,  6000] loss: 0.001\n",
      "[26,  7000] loss: 0.001\n",
      "[26,  8000] loss: 0.001\n",
      "[26,  9000] loss: 0.001\n",
      "[26, 10000] loss: 0.001\n",
      "[26, 11000] loss: 0.001\n",
      "[26, 12000] loss: 0.001\n",
      "[27,  1000] loss: 0.001\n",
      "[27,  2000] loss: 0.001\n",
      "[27,  3000] loss: 0.001\n",
      "[27,  4000] loss: 0.000\n",
      "[27,  5000] loss: 0.000\n",
      "[27,  6000] loss: 0.000\n",
      "[27,  7000] loss: 0.000\n",
      "[27,  8000] loss: 0.001\n",
      "[27,  9000] loss: 0.001\n",
      "[27, 10000] loss: 0.000\n",
      "[27, 11000] loss: 0.000\n",
      "[27, 12000] loss: 0.001\n",
      "[28,  1000] loss: 0.001\n",
      "[28,  2000] loss: 0.001\n",
      "[28,  3000] loss: 0.001\n"
     ]
    }
   ],
   "source": [
    "# train the CNN\n",
    "for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_data_loader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 1000 == 999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 1000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03bfd7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in eval_data_loader:\n",
    "        images, labels = data\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the %d test images: %d %%' % (len(eval_dataset), 100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845bbabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e62d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_correct = [0] * 10\n",
    "class_total = [0] * 10\n",
    "with torch.no_grad():\n",
    "    for data in eval_data_loader:\n",
    "        images, labels = data\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(len(labels)):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "for i in range(10):\n",
    "    print('Accuracy of %5s : %2d %%' % (\n",
    "        classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec19fcc1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
