{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf3b6ef8",
   "metadata": {},
   "source": [
    "## Appendix-5: Random Forest \n",
    "\n",
    "Random Forest is an ensemble learning algorithm that combines multiple decision trees to improve the classification accuracy and reduce overfitting. It works by creating random subsets of the data and features for each tree, then aggregating the predictions of all trees. \n",
    "\n",
    "For our implementation, we used scikit-learn's RandomForestClassifier with 1000 trees and default hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10dea8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import library dependencies\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a47a2df",
   "metadata": {},
   "source": [
    "#### Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c753635c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_PATH='../'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e8ccef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to open pickle file\n",
    "def unpickle(file):\n",
    "    import pickle\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4dcc00d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# store each pickle files in individual batches\n",
    "batch1 = unpickle(ROOT_PATH+\"cifar-10-batches-py/data_batch_1\")\n",
    "batch2 = unpickle(ROOT_PATH+\"cifar-10-batches-py/data_batch_2\")\n",
    "batch3 = unpickle(ROOT_PATH+\"cifar-10-batches-py/data_batch_3\")\n",
    "batch4 = unpickle(ROOT_PATH+\"cifar-10-batches-py/data_batch_4\")\n",
    "batch5 = unpickle(ROOT_PATH+\"cifar-10-batches-py/data_batch_5\")\n",
    "test_batch = unpickle(ROOT_PATH+\"cifar-10-batches-py/test_batch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66a05f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to create labels and images from data\n",
    "def load_data0(btch):\n",
    "    labels = btch[b'labels']\n",
    "    imgs = btch[b'data'].reshape((-1, 32, 32, 3))\n",
    "    \n",
    "    res = []\n",
    "    for ii in range(imgs.shape[0]):\n",
    "        img = imgs[ii].copy()\n",
    "        img = np.fliplr(np.rot90(np.transpose(img.flatten().reshape(3,32,32)), k=-1))\n",
    "        res.append(img)\n",
    "    imgs = np.stack(res)\n",
    "    return labels, imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "33a636f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to load data into training and test set\n",
    "def load_data():\n",
    "    x_train_l = []\n",
    "    y_train_l = []\n",
    "    for ibatch in [batch1, batch2, batch3, batch4, batch5]:\n",
    "        labels, imgs = load_data0(ibatch)\n",
    "        x_train_l.append(imgs)\n",
    "        y_train_l.extend(labels)\n",
    "    x_train = np.vstack(x_train_l)\n",
    "    y_train = np.vstack(y_train_l)\n",
    "    \n",
    "    x_test_l = []\n",
    "    y_test_l = []\n",
    "    labels, imgs = load_data0(test_batch)\n",
    "    x_test_l.append(imgs)\n",
    "    y_test_l.extend(labels)\n",
    "    x_test = np.vstack(x_test_l)\n",
    "    y_test = np.vstack(y_test_l)\n",
    "    return (x_train, y_train), (x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7cd84a",
   "metadata": {},
   "source": [
    "#### Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a84a95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create training and test set\n",
    "(x_train, y_train), (x_test, y_test) = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "466837bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "y_train shape: (50000, 1)\n",
      "x_test shape: (10000, 32, 32, 3)\n",
      "y_test shape: (10000, 1)\n"
     ]
    }
   ],
   "source": [
    "print('x_train shape:', x_train.shape)\n",
    "print('y_train shape:', y_train.shape)\n",
    "print('x_test shape:', x_test.shape)\n",
    "print('y_test shape:', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "529c78cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000 train samples (x)\n",
      "50000 train samples (y)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape[0], 'train samples (x)')\n",
    "print(y_train.shape[0], 'train samples (y)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bfefa9ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 test samples (x)\n",
      "10000 test samples (y)\n"
     ]
    }
   ],
   "source": [
    "print(x_test.shape[0], 'test samples (x)')\n",
    "print(y_test.shape[0], 'test samples (y)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d9dda58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the images\n",
    "X_train = x_train.reshape(x_train.shape[0], -1)\n",
    "X_test = x_test.reshape(x_test.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8bc2396c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data\n",
    "X_train = X_train.astype('float32') / 255\n",
    "X_test = X_test.astype('float32') / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a43cc70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape y_train and y_test to 1d arrays\n",
    "y_train = y_train.ravel()\n",
    "y_test = y_test.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "663edcb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f45b65b9",
   "metadata": {},
   "source": [
    "#### Define model and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f92c33ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "rf = RandomForestClassifier(n_estimators=1000, n_jobs=-1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7f78e83b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    7.3s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   38.8s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:  3.6min finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(n_estimators=1000, n_jobs=-1, verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(n_estimators=1000, n_jobs=-1, verbose=1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(n_estimators=1000, n_jobs=-1, verbose=1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6002b905",
   "metadata": {},
   "source": [
    "#### Save and load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0fba3bd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['random_forest.sav']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the model to a file\n",
    "joblib.dump(rf, 'random_forest.sav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7990cea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved model from a file\n",
    "loaded_model = joblib.load('random_forest.sav')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ba4119",
   "metadata": {},
   "source": [
    "#### Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bfcf352e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=8)]: Done 784 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=8)]: Done 1000 out of 1000 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=8)]: Done 784 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=8)]: Done 1000 out of 1000 | elapsed:    1.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=8)]: Done 784 tasks      | elapsed:    0.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 1.0000\n",
      "Val Accuracy: 0.4887\n",
      "Test Accuracy: 0.4888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done 1000 out of 1000 | elapsed:    1.0s finished\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "train_acc = accuracy_score(y_train, loaded_model.predict(X_train))\n",
    "val_acc = accuracy_score(y_val, loaded_model.predict(X_val))\n",
    "test_acc = accuracy_score(y_test, loaded_model.predict(X_test))\n",
    "\n",
    "print(f\"Train Accuracy: {train_acc:.4f}\")\n",
    "print(f\"Val Accuracy: {val_acc:.4f}\")\n",
    "print(f\"Test Accuracy: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b4b6eea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=8)]: Done 784 tasks      | elapsed:    0.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Precision: 0.4850\n",
      "Test Recall: 0.4888\n",
      "Test F1 score: 0.4839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done 1000 out of 1000 | elapsed:    1.0s finished\n"
     ]
    }
   ],
   "source": [
    "# Calculate precision, recall, and F1 score on test set\n",
    "test_pred = loaded_model.predict(X_test)\n",
    "precision = precision_score(y_test, test_pred, average='weighted')\n",
    "recall = recall_score(y_test, test_pred, average='weighted')\n",
    "f1 = f1_score(y_test, test_pred, average='weighted')\n",
    "\n",
    "print(f\"Test Precision: {precision:.4f}\")\n",
    "print(f\"Test Recall: {recall:.4f}\")\n",
    "print(f\"Test F1 score: {f1:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
